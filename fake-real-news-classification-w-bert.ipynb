{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tanat94/fake-real-news-classification-w-bert?scriptVersionId=115440008\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"<a href=\"https://colab.research.google.com/github/tanat1994/Fake-news-Classification/blob/main/Fake_True_News_Classification_with_DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='0'></a>\n# TABLE OF CONTENTS\n- [1. Environment Setup](#1)\n- [2. Import Libraries](#2)\n- [3. Add Dataframe label & Merge](#3)\n- [4. Exploratory Data Analysis(EDA)](#4)\n- [5. Dataframe Preprocessing](#5)\n    - [5.1 Tokenize function](#5.1)\n    - [5.2 Split Train/Test](#5.2)\n    - [5.3 Encode/Tokenize dataset](#5.3)\n- [6. Modeling](#6)\n- [7. Evaluation](#7)\n    - [7.1 DistilBERT results](#7.1)\n    - [7.2 BertBased results](#7.2)","metadata":{"id":"8lavMyHMlEHP"}},{"cell_type":"markdown","source":"<a name='1'></a>\n## 1. Environment Setup\n[Back to TOC](#0)","metadata":{"id":"shmhDgnTOqow"}},{"cell_type":"code","source":"!pip install -q transformers\n!pip install -q kaggle","metadata":{"id":"bh4r5mg1DPwS","outputId":"627585cd-8ad0-4e2f-b3cb-dc4160c6547f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import files\nfiles.upload()","metadata":{"id":"8y21p-IyE7Fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json","metadata":{"id":"d8JITnqlFAfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! kaggle datasets list\n!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset","metadata":{"id":"BJKB5RdyFxYd","outputId":"37b70cc6-652c-40f3-b67f-07b075fe1f88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip fake-and-real-news-dataset.zip","metadata":{"id":"mpCeJL2WGTpQ","outputId":"a7f0822e-dd38-494c-bae6-f6ecb52976a2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='2'></a>\n## 2. Import Libraries\n[Back to TOC](#0)","metadata":{"id":"HGrcuiDEO2Xl"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport transformers\nfrom transformers import DistilBertTokenizer, TFDistilBertModel, TFDistilBertForSequenceClassification, BertTokenizer, TFBertModel, TFBertForSequenceClassification\n\nimport tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense","metadata":{"id":"OWuce_3aOuSU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='3'></a>\n## 3. Add Dataframe label & Merge\n[Back to TOC](#0)","metadata":{"id":"znk36nnWmDXX"}},{"cell_type":"code","source":"true_df = pd.read_csv('True.csv')\nfake_df = pd.read_csv('Fake.csv')","metadata":{"id":"gSbbh8ERO1GL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_df.shape, fake_df.shape","metadata":{"id":"lgloKFHoO_6o","outputId":"c8981b92-0b1b-44c8-c8ff-7d006bbbf4ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_df['label'] = 1\nfake_df['label'] = 0\nfull_df = pd.concat([true_df, fake_df], axis=0)","metadata":{"id":"QG_xr40tPPH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.shape","metadata":{"id":"aIDG4LaFPXpx","outputId":"5869cf02-5dd5-4391-da9f-e8e1c1f1e52d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.head()","metadata":{"id":"xXKniOvOPYk8","outputId":"02dfbea2-faa0-4b68-b861-27007106d01e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='4'></a>\n## 4. Exploratory Data Analysis(EDA)\n[Back to TOC](#0)","metadata":{"id":"Pr-xq4buPmpG"}},{"cell_type":"code","source":"sns.countplot(data=full_df, x='label')","metadata":{"id":"ZEjhSNCrqiWw","outputId":"9e2550e8-8ba3-42e3-fc31-3df1aa128c0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\norder_by_subject = full_df['subject'].value_counts().sort_values(ascending=False).index\nsns.countplot(data=full_df, x='subject', order=order_by_subject)","metadata":{"id":"SUvCFHESPjE0","outputId":"e21379b9-c850-4816-8943-c6921ffb6657"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.countplot(data=full_df, x='subject', hue='label')","metadata":{"id":"rGNS_8pTPskQ","outputId":"ca932c84-1d99-4ec6-8936-ab03a2309cbe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.groupby(['subject', 'label'], sort=False)['label'].count()","metadata":{"id":"VxLNu8CQQY6T","outputId":"9bfc29b6-4969-4f16-d303-65a80a473555"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='5'></a>\n## 5. Dataframe Preprocessing\n[Back to TOC](#0)","metadata":{"id":"finVfosImlNs"}},{"cell_type":"code","source":"full_df = full_df.drop(columns=['text', 'subject', 'date'])\nfull_df.head(2)","metadata":{"id":"c5DEipVBRKho","outputId":"e45f3033-18ed-4b9d-ddb8-90bfbb194534"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df['title_len'] = full_df['title'].str.split().str.len()\nfull_df.sample(3, random_state=42)","metadata":{"id":"u0ZRzCDtUZcp","outputId":"f59d0c81-6e04-49b3-a0e6-17b293857fb6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 42","metadata":{"id":"b9B2O_U9UlTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"id":"d1zHV90DVBhE","outputId":"177fc086-8584-4782-ff1a-73d806aad5f0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='5.1'></a>\n### 5.1 Tokenize Function\n[Back to TOC](#0)","metadata":{"id":"YuhI85YVn0Qo"}},{"cell_type":"code","source":"MAX_LENGTH = 64 #42 # maxlength for new's topic\ndef tokenize_word(text):\n  toks = tokenizer(text, \n                   max_length=MAX_LENGTH, \n                   padding='max_length', \n                   truncation=True, \n                   return_tensors='tf')\n  toks = {\n      'input_ids': toks['input_ids'][0],\n      'attention_mask': toks['attention_mask'][0]\n  }\n  return toks","metadata":{"id":"xeRPnuHkWNBj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inputs_tokenizer(df):\n  input_ids = []\n  attention_masks = []\n  for title in df['title'].tolist():\n    tokens = tokenize_word(title)\n    input_ids.append(tokens['input_ids'])\n    attention_masks.append(tokens['attention_mask'])\n  \n  inputs = {\n      'input_ids': np.asarray(input_ids, dtype='int32'),\n      'attention_mask': np.asarray(attention_masks, dtype='int32')\n  }\n  return inputs","metadata":{"id":"2vgn16LXW3gO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='5.2'></a>\n### 5.2 Split Train/Test\n`Training 80%`\n\n`Validation 20%`\n\n[Back to TOC](#0)","metadata":{"id":"Zag7zr37oERz"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(full_df.drop(columns=['label']), full_df['label'], test_size=0.2, stratify=full_df['label'], random_state=42)","metadata":{"id":"CnhidrL-19iT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"id":"jluP1KLD2C60","outputId":"0d58ad91-b022-49d7-81f8-3eddcdc126c8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='5.3'></a>\n### 5.3 Encode/Tokenize dataset\n\nTokenize each sentence and add special token [CLS], [SEP]\n\n[Back to TOC](#0)","metadata":{"id":"HiyeNl2UoVS1"}},{"cell_type":"code","source":"X_train_inputs = inputs_tokenizer(X_train)\nX_test_inputs = inputs_tokenizer(X_test)","metadata":{"id":"IB6e2ta63EHb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='6'></a>\n## 6. Modeling\n[Back to TOC](#0)","metadata":{"id":"w5tJRoXuojPD"}},{"cell_type":"markdown","source":"**Model Summary**\n- Pre-trained Model => `distilbert-base-uncased | bert-base-uncased`\n  - trainable = `True | False` \n- Dropout => `0.1`\n- Epochs => `3 (4 cause overfitting)`\n    - learning rates => `[3e-4, 1e-4, 5e-5, 3e-5]` # value from BERT paper\n    - batch sizes => `8, 16, 32, 64, 128`\n    - ref. [https://github.com/google-research/bert](https://github.com/google-research/bert)","metadata":{"id":"5V45BHvZpH3V"}},{"cell_type":"code","source":"def create_model(bert_model):\n  input_ids = Input(shape=(MAX_LENGTH,), dtype='int32', name='input_ids')\n  attention_masks = Input(shape=(MAX_LENGTH,), dtype='int32', name='attention_masks')\n\n  # TFDistilbertModel\n  embedding = bert_model(input_ids, attention_masks)[0] \n  output = Dense(32, activation='relu')(embedding[:, 0, :])\n  output = tf.keras.layers.Dropout(rate=0.1)(output)\n  output = Dense(1, activation='sigmoid')(output)\n  \n  # TFBertModel\n  # embedding = bert_model(input_ids, attention_masks)[1] #pooled output\n  # output = Dense(32, activation='relu')(embedding)\n  # output = tf.keras.layers.Dropout(rate=0.1)(output)\n  # output = Dense(1, activation='sigmoid')(output)\n\n  model = Model(inputs=[input_ids, attention_masks], outputs=output)\n  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n                loss='binary_crossentropy', \n                metrics=['accuracy'])\n  return model","metadata":{"id":"Q6piX_UWjKIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base = TFDistilBertModel.from_pretrained('distilbert-base-uncased', num_labels=2)\n# base = TFBertModel.from_pretrained('bert-base-uncased', num_labels=2)\nfor layer in base.layers:\n  layer.trainable = True\n  # layer.trainable = False\nbase.summary()","metadata":{"id":"1Rf30JLs2iwk","outputId":"70ada9ae-1d97-41ab-9d73-8c2d8825b5e0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(base)\nmodel.summary()","metadata":{"id":"U82GdVwM54Py","outputId":"99a9e9ab-51cf-4b0e-a47e-c878e6d6a668"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([X_train_inputs['input_ids'], X_train_inputs['attention_mask']], \n          y_train, \n          batch_size=64, \n          epochs=3,\n          validation_data=([X_test_inputs['input_ids'], X_test_inputs['attention_mask']], y_test))","metadata":{"id":"TmbkSotq8DNA","outputId":"113eacc5-8e25-4085-c3b6-eda71338421d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='7'></a>\n## 7. Evaluation\n[Back to TOC](#0)","metadata":{"id":"nHrwkPFGlCzO"}},{"cell_type":"code","source":"y_pred = model.predict([X_test_inputs['input_ids'], X_test_inputs['attention_mask']])","metadata":{"id":"w4Fi6eCKZnTu","outputId":"826607c4-bcda-4ae9-c22b-e78274dcd8c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.round(y_pred).astype(int).ravel()","metadata":{"id":"b11lgD4huJgM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='7.1'></a>\n###  7.1 DistilBERT results\n[Back to TOC](#0)\n\n#### Trainable = TRUE\n\n- Elapsed: `238s`\n\n- Results: `accuracy: 0.9594 - val_accuracy: 0.9835`\n\n#### Trainable = FALSE\n- Elapsed: `99s`\n\n- Results: `accuracy: 0.8286 - val_accuracy: 0.8861`","metadata":{"id":"88VTlgHyrRu1"}},{"cell_type":"markdown","source":"<a name='7.2'></a>\n### 7.2 BertBased results\n[Back to TOC](#0)\n\n#### Trainable = TRUE\n\n- Elapsed: `471s`\n\n- Results: `accuracy: 0.9871 - val_accuracy: 0.9839`\n\n#### Trainable = FALSE\n\n- Elapsed: `199s`\n\n- Results: `accuracy: 0.7195 - val_accuracy: 0.7667`","metadata":{"id":"jgXKIbIpr_2Z"}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","metadata":{"id":"Jaj3J6vebJjG","outputId":"fe8c673d-c666-4fb6-f88f-9581a01a7872"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score","metadata":{"id":"JjC7btyM8DLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_score = accuracy_score(y_test, y_pred)\nprint(f'Accuracy score = {acc_score:.2f}%')","metadata":{"id":"vqlfE6hrZ_79","outputId":"186a16f9-0290-458d-e146-e5ef4b75d182"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score = f1_score(y_test, y_pred)\nprecision_score = precision_score(y_test, y_pred)\nrecall_score = recall_score(y_test, y_pred)","metadata":{"id":"Wrt-u6JOr9tZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [['accuracy', acc_score], ['f1', f1_score], ['precision', precision_score], ['recall', recall_score]]\nmetrics_df = pd.DataFrame(scores, columns=['metrics', 'score'])\nmetrics_df","metadata":{"id":"jDYi6tsAudf2","outputId":"c2bbeb2e-cb32-464f-d0fa-fc1ff3d80c6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, np.round(y_pred).astype(int).ravel().reshape(-1, 1))\nsns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='d')","metadata":{"id":"8JT53MwAaWpO","outputId":"bd956bf3-566f-4127-a52e-9a45e357a329"},"execution_count":null,"outputs":[]}]}